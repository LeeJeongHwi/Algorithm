{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wjdgn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.7119417 [[ 3.419112   -0.13291475  0.4929202 ]\n",
      " [-0.89855665  0.907253   -0.6178503 ]\n",
      " [ 1.502978    0.6169577   0.15833265]]\n",
      "1 3.905056 [[ 3.398296   -0.14953633  0.53035754]\n",
      " [-0.8690134   0.77784944 -0.51798993]\n",
      " [ 1.5007068   0.53181005  0.24575154]]\n",
      "2 3.513998 [[ 3.3637288  -0.15236323  0.5677518 ]\n",
      " [-0.9098542   0.7189358  -0.4182356 ]\n",
      " [ 1.4307066   0.51445967  0.33310217]]\n",
      "3 3.186748 [[ 3.3322594  -0.15818323  0.60504127]\n",
      " [-0.93447554  0.64407694 -0.31875536]\n",
      " [ 1.3764106   0.48159793  0.42025992]]\n",
      "4 2.8627007 [[ 3.2996438  -0.16263422  0.6421079 ]\n",
      " [-0.9659347   0.5767307  -0.21994999]\n",
      " [ 1.3156126   0.45576715  0.5068888 ]]\n",
      "5 2.544664 [[ 3.2679923  -0.16746458  0.6785897 ]\n",
      " [-0.9933355   0.50749147 -0.12330992]\n",
      " [ 1.258784    0.42783615  0.5916482 ]]\n",
      "6 2.2461648 [[ 3.2370696  -0.17118308  0.7132308 ]\n",
      " [-1.0186901   0.4447351  -0.03519897]\n",
      " [ 1.2040435   0.40560853  0.6686164 ]]\n",
      "7 2.017641 [[ 3.208983   -0.17183112  0.7419654 ]\n",
      " [-1.0315819   0.40124133  0.02118653]\n",
      " [ 1.1617329   0.40053055  0.71600497]]\n",
      "8 1.9308999 [[ 3.1853342  -0.16779865  0.7615816 ]\n",
      " [-1.0235322   0.3882555   0.02612257]\n",
      " [ 1.1403949   0.42267162  0.71520185]]\n",
      "9 1.9014814 [[ 3.1639     -0.16491526  0.7801324 ]\n",
      " [-1.0052956   0.36987182  0.0262697 ]\n",
      " [ 1.1292374   0.43927824  0.70975274]]\n",
      "10 1.8743572 [[ 3.1426878  -0.16186632  0.7982956 ]\n",
      " [-0.9866158   0.35273063  0.02473103]\n",
      " [ 1.118739    0.4566955   0.7028339 ]]\n",
      "11 1.8476021 [[ 3.1216288  -0.15894753  0.81643593]\n",
      " [-0.9678225   0.33503783  0.02363054]\n",
      " [ 1.1085693   0.47327316  0.6964259 ]]\n",
      "12 1.8212049 [[ 3.1006656  -0.15597412  0.8344257 ]\n",
      " [-0.94922185  0.31787008  0.02219762]\n",
      " [ 1.0984476   0.49000046  0.6898203 ]]\n",
      "13 1.7951726 [[ 3.079822   -0.15304011  0.85233516]\n",
      " [-0.9307155   0.30069634  0.02086503]\n",
      " [ 1.0884795   0.50637674  0.683412  ]]\n",
      "14 1.769513 [[ 3.059089   -0.15009904  0.87012714]\n",
      " [-0.9123738   0.28380102  0.01941865]\n",
      " [ 1.0786115   0.52265537  0.6770014 ]]\n",
      "15 1.7442338 [[ 3.038476   -0.1471779   0.88781893]\n",
      " [-0.8941711   0.2670443   0.01797266]\n",
      " [ 1.0688819   0.5386965   0.67068994]]\n",
      "16 1.7193433 [[ 3.0179827  -0.14426552  0.9053999 ]\n",
      " [-0.87613386  0.25050738  0.0164723 ]\n",
      " [ 1.0592794   0.5545647   0.6644242 ]]\n",
      "17 1.6948497 [[ 2.9976141  -0.14137079  0.92287385]\n",
      " [-0.85826033  0.23415637  0.01494981]\n",
      " [ 1.0498207   0.5702174   0.65823036]]\n",
      "18 1.6707603 [[ 2.9773722  -0.13849217  0.94023716]\n",
      " [-0.8405646   0.21801792  0.01339255]\n",
      " [ 1.040507    0.5856677   0.6520937 ]]\n",
      "19 1.6470833 [[ 2.9572606  -0.13563368  0.95749015]\n",
      " [-0.8230524   0.2020872   0.01181106]\n",
      " [ 1.0313482   0.6008995   0.6460206 ]]\n",
      "20 1.6238258 [[ 2.9372823  -0.13279648  0.9746312 ]\n",
      " [-0.8057342   0.18637618  0.0102039 ]\n",
      " [ 1.0223501   0.61591184  0.64000654]]\n",
      "21 1.6009954 [[ 2.9174407  -0.1299833   0.9916597 ]\n",
      " [-0.7886182   0.17088827  0.0085758 ]\n",
      " [ 1.0135201   0.6306955   0.6340528 ]]\n",
      "22 1.578599 [[ 2.8977385  -0.12719609  1.0085747 ]\n",
      " [-0.77171385  0.15563156  0.00692818]\n",
      " [ 1.0048652   0.6452456   0.62815773]]\n",
      "23 1.556643 [[ 2.8781788  -0.12443721  1.0253755 ]\n",
      " [-0.75503     0.14061171  0.00526414]\n",
      " [ 0.9963922   0.65955496  0.62232137]]\n",
      "24 1.5351331 [[ 2.8587646  -0.12170882  1.0420612 ]\n",
      " [-0.7385757   0.12583585  0.00358571]\n",
      " [ 0.9881079   0.67361766  0.6165429 ]]\n",
      "25 1.514075 [[ 2.8394990e+00 -1.1901318e-01  1.0586313e+00]\n",
      " [-7.2235978e-01  1.1131019e-01  1.8954232e-03]\n",
      " [ 9.8001903e-01  6.8742722e-01  6.1082220e-01]]\n",
      "26 1.4934733 [[ 2.8203845e+00 -1.1635244e-01  1.0750852e+00]\n",
      " [-7.0639092e-01  9.7041480e-02  1.9529602e-04]\n",
      " [ 9.7213179e-01  7.0097774e-01  6.0515893e-01]]\n",
      "27 1.4733317 [[ 2.8014238e+00 -1.1372875e-01  1.0914221e+00]\n",
      " [-6.9067758e-01  8.3036005e-02 -1.5125719e-03]\n",
      " [ 9.6445221e-01  7.1426338e-01  5.9955293e-01]]\n",
      "28 1.4536536 [[ 2.7826197  -0.1111442   1.1076417 ]\n",
      " [-0.67522776  0.06929987 -0.00322626]\n",
      " [ 0.9569859   0.7272785   0.59400415]]\n",
      "29 1.4344411 [[ 2.7639744  -0.10860077  1.1237434 ]\n",
      " [-0.6600492   0.05583915 -0.00494411]\n",
      " [ 0.94973797  0.74001795  0.58851266]]\n",
      "30 1.4156954 [[ 2.7454906  -0.10610037  1.1397269 ]\n",
      " [-0.645149    0.04265936 -0.00666453]\n",
      " [ 0.9427131   0.75247693  0.58307856]]\n",
      "31 1.3974171 [[ 2.7271702  -0.1036448   1.1555917 ]\n",
      " [-0.63053375  0.02976578 -0.00838619]\n",
      " [ 0.9359154   0.7646511   0.57770205]]\n",
      "32 1.3796053 [[ 2.7090154  -0.10123575  1.1713376 ]\n",
      " [-0.6162095   0.01716322 -0.01010786]\n",
      " [ 0.92934847  0.7765367   0.5723834 ]]\n",
      "33 1.3622582 [[ 2.6910279  -0.09887475  1.1869642 ]\n",
      " [-0.6021816   0.00485597 -0.01182854]\n",
      " [ 0.9230151   0.7881304   0.567123  ]]\n",
      "34 1.3453732 [[ 2.6732092  -0.0965632   1.2024711 ]\n",
      " [-0.5884546  -0.00715219 -0.0135474 ]\n",
      " [ 0.9169177   0.79942954  0.5619213 ]]\n",
      "35 1.3289461 [[ 2.655561   -0.09430233  1.2178584 ]\n",
      " [-0.5750323  -0.018858   -0.01526388]\n",
      " [ 0.9110577   0.81043214  0.55677867]]\n",
      "36 1.3129725 [[ 2.6380847  -0.09209323  1.2331257 ]\n",
      " [-0.5619177  -0.03025898 -0.01697747]\n",
      " [ 0.90543616  0.8211368   0.5516956 ]]\n",
      "37 1.2974467 [[ 2.620781   -0.08993681  1.2482729 ]\n",
      " [-0.5491131  -0.04135317 -0.0186879 ]\n",
      " [ 0.9000532   0.8315427   0.5466726 ]]\n",
      "38 1.2823616 [[ 2.603651   -0.08783378  1.2632998 ]\n",
      " [-0.53661984 -0.05213925 -0.02039511]\n",
      " [ 0.8949084   0.8416499   0.54171014]]\n",
      "39 1.2677099 [[ 2.5866954  -0.08578473  1.2782063 ]\n",
      " [-0.5244384  -0.06261675 -0.02209905]\n",
      " [ 0.89000076  0.8514589   0.5368088 ]]\n",
      "40 1.2534835 [[ 2.5699146  -0.08379004  1.2929925 ]\n",
      " [-0.51256853 -0.0727857  -0.02379996]\n",
      " [ 0.8853284   0.8609711   0.53196895]]\n",
      "41 1.2396731 [[ 2.5533087  -0.08184994  1.3076582 ]\n",
      " [-0.5010091  -0.08264695 -0.02549813]\n",
      " [ 0.8808892   0.87018824  0.52719104]]\n",
      "42 1.2262692 [[ 2.536878   -0.07996447  1.3222034 ]\n",
      " [-0.48975834 -0.09220188 -0.02719394]\n",
      " [ 0.8766801   0.87911284  0.52247554]]\n",
      "43 1.2132618 [[ 2.5206223  -0.07813352  1.3366282 ]\n",
      " [-0.47881377 -0.10145252 -0.02888788]\n",
      " [ 0.87269765  0.88774806  0.51782274]]\n",
      "44 1.2006407 [[ 2.5045412  -0.07635686  1.3509326 ]\n",
      " [-0.46817192 -0.11040172 -0.03058051]\n",
      " [ 0.86893815  0.8960973   0.513233  ]]\n",
      "45 1.1883945 [[ 2.488634   -0.07463406  1.3651167 ]\n",
      " [-0.45782918 -0.11905252 -0.03227245]\n",
      " [ 0.8653971   0.90416485  0.5087065 ]]\n",
      "46 1.1765127 [[ 2.4729006  -0.07296464  1.3791807 ]\n",
      " [-0.4477809  -0.12740895 -0.0339643 ]\n",
      " [ 0.8620699   0.911955    0.50424355]]\n",
      "47 1.1649837 [[ 2.4573398  -0.0713479   1.3931247 ]\n",
      " [-0.43802235 -0.13547504 -0.03565679]\n",
      " [ 0.8589514   0.91947293  0.49984416]]\n",
      "48 1.1537964 [[ 2.4419508  -0.06978312  1.4069489 ]\n",
      " [-0.4285479  -0.14325574 -0.03735054]\n",
      " [ 0.85603637  0.92672366  0.49550846]]\n",
      "49 1.1429398 [[ 2.4267323  -0.0682694   1.4206537 ]\n",
      " [-0.41935197 -0.15075596 -0.03904627]\n",
      " [ 0.85331905  0.93371296  0.49123645]]\n",
      "50 1.1324022 [[ 2.411683   -0.06680582  1.4342393 ]\n",
      " [-0.4104283  -0.1579813  -0.04074462]\n",
      " [ 0.85079384  0.94044656  0.48702806]]\n",
      "51 1.1221726 [[ 2.396802   -0.06539135  1.447706  ]\n",
      " [-0.40177047 -0.16493751 -0.04244622]\n",
      " [ 0.8484548   0.9469305   0.4828832 ]]\n",
      "52 1.1122401 [[ 2.3820872  -0.06402487  1.4610542 ]\n",
      " [-0.39337197 -0.17163058 -0.04415168]\n",
      " [ 0.8462958   0.9531711   0.4788016 ]]\n",
      "53 1.1025943 [[ 2.3675375  -0.06270525  1.4742843 ]\n",
      " [-0.3852259  -0.17806675 -0.04586159]\n",
      " [ 0.8443108   0.9591746   0.47478306]]\n",
      "54 1.093224 [[ 2.353151   -0.06143128  1.4873968 ]\n",
      " [-0.37732542 -0.18425238 -0.04757643]\n",
      " [ 0.84249365  0.96494746  0.47082728]]\n",
      "55 1.0841197 [[ 2.338926   -0.06020174  1.5003923 ]\n",
      " [-0.36966345 -0.19019412 -0.04929668]\n",
      " [ 0.8408383   0.97049624  0.46693388]]\n",
      "56 1.0752711 [[ 2.3248608  -0.05901535  1.5132712 ]\n",
      " [-0.362233   -0.19589849 -0.05102274]\n",
      " [ 0.8393386   0.97582746  0.46310243]]\n",
      "57 1.0666684 [[ 2.3109534  -0.05787083  1.5260342 ]\n",
      " [-0.35502702 -0.20137222 -0.05275498]\n",
      " [ 0.8379885   0.98094755  0.45933244]]\n",
      "58 1.0583026 [[ 2.2972016  -0.05676689  1.538682  ]\n",
      " [-0.34803846 -0.20662203 -0.05449371]\n",
      " [ 0.83678204  0.9858631   0.45562336]]\n",
      "59 1.0501647 [[ 2.2836037  -0.0557022   1.5512152 ]\n",
      " [-0.34126043 -0.2116546  -0.05623916]\n",
      " [ 0.8357133   0.9905805   0.45197466]]\n",
      "60 1.0422456 [[ 2.2701576  -0.05467546  1.5636345 ]\n",
      " [-0.334686   -0.21647662 -0.05799156]\n",
      " [ 0.83477676  0.99510616  0.44838563]]\n",
      "61 1.0345378 [[ 2.2568612  -0.05368537  1.5759407 ]\n",
      " [-0.32830852 -0.22109468 -0.05975099]\n",
      " [ 0.8339665   0.99944633  0.4448557 ]]\n",
      "62 1.0270329 [[ 2.2437124  -0.05273063  1.5881346 ]\n",
      " [-0.3221212  -0.22551543 -0.06151757]\n",
      " [ 0.8332772   1.0036072   0.44138408]]\n",
      "63 1.0197229 [[ 2.2307093  -0.05180995  1.6002171 ]\n",
      " [-0.31611767 -0.2297452  -0.06329133]\n",
      " [ 0.83270353  1.007595    0.43797004]]\n",
      "64 1.0126011 [[ 2.2178495  -0.05092208  1.612189  ]\n",
      " [-0.31029147 -0.23379056 -0.06507217]\n",
      " [ 0.8322404   1.0114152   0.43461287]]\n",
      "65 1.00566 [[ 2.2051308  -0.05006573  1.6240513 ]\n",
      " [-0.30463654 -0.23765752 -0.06686012]\n",
      " [ 0.8318826   1.0150743   0.43131167]]\n",
      "66 0.9988931 [[ 2.1925511  -0.04923973  1.6358049 ]\n",
      " [-0.29914665 -0.24135248 -0.06865504]\n",
      " [ 0.8316256   1.0185773   0.4280656 ]]\n",
      "67 0.9922937 [[ 2.1801083  -0.04844282  1.6474507 ]\n",
      " [-0.29381618 -0.24488121 -0.07045678]\n",
      " [ 0.83146447  1.0219302   0.42487383]]\n",
      "68 0.98585594 [[ 2.1678002  -0.04767385  1.6589898 ]\n",
      " [-0.28863934 -0.24824968 -0.07226515]\n",
      " [ 0.83139485  1.0251383   0.42173544]]\n",
      "69 0.9795741 [[ 2.1556246  -0.04693168  1.6704232 ]\n",
      " [-0.28361064 -0.25146365 -0.07407988]\n",
      " [ 0.83141243  1.0282066   0.41864955]]\n",
      "70 0.97344214 [[ 2.1435795  -0.04621517  1.6817517 ]\n",
      " [-0.2787248  -0.25452858 -0.07590077]\n",
      " [ 0.83151305  1.0311403   0.4156152 ]]\n",
      "71 0.9674548 [[ 2.1316626  -0.04552323  1.6929767 ]\n",
      " [-0.27397668 -0.25744995 -0.07772751]\n",
      " [ 0.83169276  1.0339444   0.41263148]]\n",
      "72 0.96160716 [[ 2.1198719  -0.04485479  1.704099  ]\n",
      " [-0.2693614  -0.26023293 -0.0795598 ]\n",
      " [ 0.8319477   1.0366236   0.40969738]]\n",
      "73 0.9558941 [[ 2.108205   -0.04420884  1.71512   ]\n",
      " [-0.26487404 -0.26288283 -0.08139727]\n",
      " [ 0.8322743   1.0391823   0.406812  ]]\n",
      "74 0.950311 [[ 2.0966601  -0.04358434  1.7260405 ]\n",
      " [-0.26051024 -0.26540425 -0.08323964]\n",
      " [ 0.8326689   1.0416255   0.40397426]]\n",
      "75 0.9448534 [[ 2.0852349  -0.04298038  1.7368617 ]\n",
      " [-0.25626522 -0.26780242 -0.08508647]\n",
      " [ 0.8331285   1.0439569   0.40118328]]\n",
      "76 0.93951714 [[ 2.0739274  -0.04239594  1.7475848 ]\n",
      " [-0.25213513 -0.27008155 -0.08693741]\n",
      " [ 0.8336496   1.0461812   0.39843798]]\n",
      "77 0.9342978 [[ 2.0627356  -0.04183019  1.7582109 ]\n",
      " [-0.24811554 -0.2722465  -0.088792  ]\n",
      " [ 0.83422935  1.048302    0.3957374 ]]\n",
      "78 0.92919177 [[ 2.0516574  -0.04128218  1.768741  ]\n",
      " [-0.24420278 -0.27430138 -0.09064989]\n",
      " [ 0.8348647   1.0503236   0.39308056]]\n",
      "79 0.924195 [[ 2.040691   -0.04075112  1.7791765 ]\n",
      " [-0.24039285 -0.27625057 -0.09251061]\n",
      " [ 0.83555305  1.0522493   0.39046645]]\n",
      "80 0.91930425 [[ 2.029834   -0.04023613  1.7895182 ]\n",
      " [-0.23668231 -0.2780979  -0.0943738 ]\n",
      " [ 0.8362916   1.0540831   0.38789403]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 0.914516 [[ 2.019085   -0.03973647  1.7997676 ]\n",
      " [-0.2330675  -0.27984753 -0.09623897]\n",
      " [ 0.8370781   1.0558283   0.38536236]]\n",
      "82 0.9098266 [[ 2.0084417  -0.03925134  1.8099257 ]\n",
      " [-0.22954524 -0.28150308 -0.09810568]\n",
      " [ 0.8379099   1.0574884   0.38287047]]\n",
      "83 0.9052334 [[ 1.9979025  -0.03878003  1.8199936 ]\n",
      " [-0.22611217 -0.2830683  -0.09997353]\n",
      " [ 0.8387849   1.0590665   0.38041732]]\n",
      "84 0.900733 [[ 1.9874654  -0.0383218   1.8299725 ]\n",
      " [-0.2227653  -0.28454664 -0.10184205]\n",
      " [ 0.8397009   1.060566    0.378002  ]]\n",
      "85 0.8963227 [[ 1.9771285  -0.037876    1.8398635 ]\n",
      " [-0.21950167 -0.28594154 -0.1037108 ]\n",
      " [ 0.8406558   1.0619895   0.3756235 ]]\n",
      "86 0.8919997 [[ 1.9668901  -0.03744195  1.8496679 ]\n",
      " [-0.2163184  -0.28725627 -0.10557935]\n",
      " [ 0.84164774  1.0633403   0.37328088]]\n",
      "87 0.8877613 [[ 1.9567485  -0.03701903  1.8593867 ]\n",
      " [-0.2132128  -0.28849396 -0.10744725]\n",
      " [ 0.8426748   1.064621    0.3709732 ]]\n",
      "88 0.8836049 [[ 1.9467018  -0.03660662  1.8690209 ]\n",
      " [-0.21018225 -0.28965768 -0.1093141 ]\n",
      " [ 0.8437352   1.0658343   0.3686995 ]]\n",
      "89 0.87952805 [[ 1.9367484  -0.03620413  1.8785719 ]\n",
      " [-0.20722422 -0.29075035 -0.11117945]\n",
      " [ 0.84482735  1.0669827   0.36645886]]\n",
      "90 0.87552845 [[ 1.9268866  -0.03581101  1.8880405 ]\n",
      " [-0.20433639 -0.29177475 -0.11304289]\n",
      " [ 0.8459496   1.068069    0.36425042]]\n",
      "91 0.87160385 [[ 1.9171147  -0.03542671  1.897428  ]\n",
      " [-0.20151633 -0.29273367 -0.11490401]\n",
      " [ 0.84710044  1.0690953   0.36207324]]\n",
      "92 0.86775196 [[ 1.9074312  -0.03505071  1.9067355 ]\n",
      " [-0.19876197 -0.29362965 -0.11676241]\n",
      " [ 0.8482784   1.0700641   0.35992643]]\n",
      "93 0.8639708 [[ 1.8978345  -0.03468252  1.9159641 ]\n",
      " [-0.19607103 -0.29446533 -0.11861767]\n",
      " [ 0.84948224  1.0709776   0.35780913]]\n",
      "94 0.8602582 [[ 1.888323   -0.03432164  1.9251148 ]\n",
      " [-0.19344161 -0.29524302 -0.12046938]\n",
      " [ 0.8507105   1.0718379   0.35572052]]\n",
      "95 0.8566123 [[ 1.878895   -0.03396765  1.9341886 ]\n",
      " [-0.19087163 -0.2959652  -0.1223172 ]\n",
      " [ 0.85196215  1.0726471   0.35365975]]\n",
      "96 0.85303134 [[ 1.8695494  -0.03362006  1.9431868 ]\n",
      " [-0.18835935 -0.29663393 -0.12416074]\n",
      " [ 0.8532358   1.0734072   0.35162598]]\n",
      "97 0.8495134 [[ 1.8602844  -0.03327847  1.9521102 ]\n",
      " [-0.18590286 -0.29725152 -0.12599964]\n",
      " [ 0.85453045  1.07412     0.3496184 ]]\n",
      "98 0.8460567 [[ 1.8510988  -0.03294247  1.9609599 ]\n",
      " [-0.18350045 -0.29782    -0.12783356]\n",
      " [ 0.8558451   1.0747876   0.34763625]]\n",
      "99 0.8426597 [[ 1.841991   -0.03261168  1.9697369 ]\n",
      " [-0.18115051 -0.2983414  -0.12966211]\n",
      " [ 0.8571786   1.0754116   0.34567878]]\n",
      "100 0.83932066 [[ 1.8329597  -0.03228571  1.9784423 ]\n",
      " [-0.17885138 -0.29881763 -0.13148502]\n",
      " [ 0.85853016  1.0759937   0.34374517]]\n",
      "101 0.8360381 [[ 1.8240035  -0.03196421  1.987077  ]\n",
      " [-0.17660154 -0.29925057 -0.13330191]\n",
      " [ 0.85989875  1.0765356   0.3418347 ]]\n",
      "102 0.8328105 [[ 1.815121   -0.03164684  1.9956421 ]\n",
      " [-0.17439948 -0.2996421  -0.13511248]\n",
      " [ 0.8612836   1.0770388   0.33994666]]\n",
      "103 0.82963634 [[ 1.8063111  -0.03133326  2.0041385 ]\n",
      " [-0.17224391 -0.2999937  -0.13691643]\n",
      " [ 0.8626837   1.077505    0.33808032]]\n",
      "104 0.8265143 [[ 1.7975725  -0.03102318  2.012567  ]\n",
      " [-0.1701332  -0.30030736 -0.13871348]\n",
      " [ 0.8640986   1.0779353   0.33623502]]\n",
      "105 0.8234431 [[ 1.7889038  -0.03071623  2.0209289 ]\n",
      " [-0.16806641 -0.30058426 -0.14050335]\n",
      " [ 0.8655272   1.0783317   0.33441004]]\n",
      "106 0.8204213 [[ 1.780304   -0.03041223  2.0292246 ]\n",
      " [-0.16604184 -0.30082643 -0.14228573]\n",
      " [ 0.8669692   1.0786949   0.3326048 ]]\n",
      "107 0.81744766 [[ 1.7717717  -0.03011078  2.0374556 ]\n",
      " [-0.16405882 -0.3010348  -0.1440604 ]\n",
      " [ 0.8684234   1.0790269   0.3308186 ]]\n",
      "108 0.8145211 [[ 1.7633058  -0.02981174  2.0456223 ]\n",
      " [-0.16211553 -0.30121145 -0.14582707]\n",
      " [ 0.8698898   1.0793283   0.32905084]]\n",
      "109 0.81164026 [[ 1.7549051  -0.02951474  2.053726  ]\n",
      " [-0.16021147 -0.30135703 -0.14758553]\n",
      " [ 0.87136716  1.0796009   0.3273009 ]]\n",
      "110 0.80880415 [[ 1.7465687  -0.02921965  2.0617673 ]\n",
      " [-0.15834503 -0.3014735  -0.1493355 ]\n",
      " [ 0.8728554   1.0798453   0.32556823]]\n",
      "111 0.80601156 [[ 1.7382952  -0.02892613  2.0697472 ]\n",
      " [-0.1565156  -0.3015616  -0.15107684]\n",
      " [ 0.87435365  1.0800631   0.32385218]]\n",
      "112 0.80326164 [[ 1.7300837  -0.02863405  2.0776665 ]\n",
      " [-0.1547218  -0.301623   -0.15280926]\n",
      " [ 0.87586164  1.080255    0.32215226]]\n",
      "113 0.80055285 [[ 1.7219331  -0.02834312  2.0855262 ]\n",
      " [-0.15296301 -0.30165845 -0.1545326 ]\n",
      " [ 0.8773786   1.0804224   0.32046786]]\n",
      "114 0.7978848 [[ 1.7138425  -0.0280532   2.093327  ]\n",
      " [-0.15123793 -0.30166948 -0.15624666]\n",
      " [ 0.8789044   1.0805659   0.31879848]]\n",
      "115 0.79525614 [[ 1.7058107  -0.02776404  2.1010697 ]\n",
      " [-0.14954607 -0.30165675 -0.15795124]\n",
      " [ 0.8804382   1.0806869   0.31714365]]\n",
      "116 0.7926661 [[ 1.6978368  -0.02747552  2.108755  ]\n",
      " [-0.14788614 -0.30162174 -0.15964618]\n",
      " [ 0.88197994  1.080786    0.31550282]]\n",
      "117 0.7901137 [[ 1.6899198  -0.0271874   2.116384  ]\n",
      " [-0.14625765 -0.30156508 -0.16133131]\n",
      " [ 0.88352895  1.0808643   0.31387553]]\n",
      "118 0.7875981 [[ 1.6820588  -0.02689957  2.1239572 ]\n",
      " [-0.14465956 -0.30148804 -0.16300645]\n",
      " [ 0.885085    1.0809225   0.3122613 ]]\n",
      "119 0.7851183 [[ 1.6742529  -0.02661182  2.1314754 ]\n",
      " [-0.14309125 -0.3013913  -0.1646715 ]\n",
      " [ 0.8866475   1.0809616   0.3106597 ]]\n",
      "120 0.78267384 [[ 1.666501   -0.02632404  2.1389394 ]\n",
      " [-0.14155173 -0.301276   -0.1663263 ]\n",
      " [ 0.8882165   1.0809821   0.30907026]]\n",
      "121 0.7802635 [[ 1.6588025  -0.02603604  2.14635   ]\n",
      " [-0.14004065 -0.3011427  -0.1679707 ]\n",
      " [ 0.88979113  1.0809851   0.30749258]]\n",
      "122 0.7778867 [[ 1.6511564  -0.02574772  2.1537077 ]\n",
      " [-0.13855691 -0.30099252 -0.16960463]\n",
      " [ 0.89137155  1.080971    0.3059262 ]]\n",
      "123 0.77554274 [[ 1.6435618  -0.02545891  2.1610136 ]\n",
      " [-0.13710015 -0.30082598 -0.17122795]\n",
      " [ 0.8929571   1.0809408   0.30437076]]\n",
      "124 0.7732307 [[ 1.636018   -0.02516953  2.168268  ]\n",
      " [-0.13566941 -0.30064413 -0.17284054]\n",
      " [ 0.89454776  1.0808951   0.30282587]]\n",
      "125 0.77094996 [[ 1.6285241  -0.02487941  2.1754718 ]\n",
      " [-0.13426436 -0.3004474  -0.1744423 ]\n",
      " [ 0.896143    1.0808345   0.30129114]]\n",
      "126 0.7687 [[ 1.6210792  -0.02458848  2.1826258 ]\n",
      " [-0.1328841  -0.3002368  -0.17603317]\n",
      " [ 0.89774287  1.0807596   0.2997662 ]]\n",
      "127 0.7664799 [[ 1.6136826  -0.0242966   2.1897304 ]\n",
      " [-0.13152829 -0.30001274 -0.17761303]\n",
      " [ 0.89934677  1.0806712   0.29825073]]\n",
      "128 0.764289 [[ 1.6063336  -0.0240037   2.1967864 ]\n",
      " [-0.13019617 -0.29977608 -0.17918183]\n",
      " [ 0.9009547   1.0805696   0.29674435]]\n",
      "129 0.7621271 [[ 1.5990314  -0.02370964  2.2037945 ]\n",
      " [-0.12888731 -0.2995273  -0.18073948]\n",
      " [ 0.9025663   1.0804557   0.29524675]]\n",
      "130 0.759993 [[ 1.5917754  -0.02341437  2.2107553 ]\n",
      " [-0.12760103 -0.29926714 -0.1822859 ]\n",
      " [ 0.9041815   1.0803295   0.29375762]]\n",
      "131 0.7578864 [[ 1.5845647  -0.02311775  2.2176695 ]\n",
      " [-0.12633705 -0.2989959  -0.18382111]\n",
      " [ 0.90579975  1.0801922   0.29227662]]\n",
      "132 0.7558067 [[ 1.5773987  -0.02281976  2.2245376 ]\n",
      " [-0.12509452 -0.29871458 -0.18534498]\n",
      " [ 0.90742135  1.0800438   0.29080352]]\n",
      "133 0.7537532 [[ 1.5702765  -0.02252026  2.2313602 ]\n",
      " [-0.12387331 -0.29842326 -0.1868575 ]\n",
      " [ 0.90904564  1.079885    0.289338  ]]\n",
      "134 0.75172555 [[ 1.5631977  -0.02221923  2.238138  ]\n",
      " [-0.12267265 -0.2981228  -0.18835862]\n",
      " [ 0.9106727   1.0797161   0.28787977]]\n",
      "135 0.7497231 [[ 1.5561615  -0.02191655  2.2448714 ]\n",
      " [-0.12149233 -0.2978134  -0.18984833]\n",
      " [ 0.91230226  1.0795377   0.28642854]]\n",
      "136 0.7477454 [[ 1.5491673  -0.0216122   2.2515612 ]\n",
      " [-0.12033162 -0.29749584 -0.19132657]\n",
      " [ 0.9139343   1.0793501   0.2849841 ]]\n",
      "137 0.74579203 [[ 1.5422144  -0.02130607  2.258208  ]\n",
      " [-0.11919042 -0.29717028 -0.19279334]\n",
      " [ 0.91556835  1.079154    0.2835462 ]]\n",
      "138 0.74386215 [[ 1.5353023  -0.02099815  2.2648122 ]\n",
      " [-0.11806796 -0.29683745 -0.19424862]\n",
      " [ 0.9172046   1.0789493   0.2821146 ]]\n",
      "139 0.7419555 [[ 1.5284302  -0.02068834  2.2713745 ]\n",
      " [-0.11696416 -0.29649746 -0.19569239]\n",
      " [ 0.9188426   1.0787369   0.28068903]]\n",
      "140 0.74007165 [[ 1.5215977  -0.02037662  2.2778952 ]\n",
      " [-0.11587837 -0.296151   -0.19712463]\n",
      " [ 0.92048246  1.0785167   0.27926934]]\n",
      "141 0.7382102 [[ 1.5148042  -0.02006292  2.284375  ]\n",
      " [-0.11481038 -0.29579827 -0.19854538]\n",
      " [ 0.92212385  1.0782894   0.27785525]]\n",
      "142 0.73637044 [[ 1.508049   -0.0197472   2.2908144 ]\n",
      " [-0.11375976 -0.2954397  -0.19995458]\n",
      " [ 0.92376673  1.0780551   0.2764466 ]]\n",
      "143 0.7345524 [[ 1.5013317  -0.01942942  2.297214  ]\n",
      " [-0.11272609 -0.29507565 -0.20135228]\n",
      " [ 0.925411    1.0778143   0.2750432 ]]\n",
      "144 0.7327551 [[ 1.4946516  -0.01910953  2.3035743 ]\n",
      " [-0.11170909 -0.29470643 -0.2027385 ]\n",
      " [ 0.9270565   1.0775672   0.2736448 ]]\n",
      "145 0.7309785 [[ 1.4880081  -0.0187875   2.3098958 ]\n",
      " [-0.11070841 -0.29433239 -0.20411323]\n",
      " [ 0.92870307  1.0773141   0.27225128]]\n",
      "146 0.72922194 [[ 1.481401   -0.01846329  2.3161788 ]\n",
      " [-0.10972369 -0.2939538  -0.20547651]\n",
      " [ 0.9303507   1.0770555   0.2708624 ]]\n",
      "147 0.72748536 [[ 1.4748294  -0.01813688  2.322424  ]\n",
      " [-0.10875461 -0.29357108 -0.20682831]\n",
      " [ 0.93199927  1.0767913   0.26947808]]\n",
      "148 0.7257681 [[ 1.4682931  -0.01780823  2.3286316 ]\n",
      " [-0.10780087 -0.29318443 -0.2081687 ]\n",
      " [ 0.93364865  1.0765219   0.2680981 ]]\n",
      "149 0.7240699 [[ 1.4617914  -0.01747729  2.3348024 ]\n",
      " [-0.10686228 -0.29279402 -0.20949769]\n",
      " [ 0.93529856  1.0762477   0.2667223 ]]\n",
      "150 0.7223904 [[ 1.4553239  -0.0171441   2.3409367 ]\n",
      " [-0.10593824 -0.29240042 -0.21081534]\n",
      " [ 0.9369493   1.0759687   0.26535052]]\n",
      "151 0.72072935 [[ 1.4488901  -0.01680855  2.347035  ]\n",
      " [-0.10502882 -0.29200354 -0.21212164]\n",
      " [ 0.9386004   1.0756855   0.26398268]]\n",
      "152 0.7190862 [[ 1.4424895  -0.01647068  2.3530977 ]\n",
      " [-0.10413344 -0.2916039  -0.21341667]\n",
      " [ 0.94025207  1.075398    0.26261857]]\n",
      "153 0.71746075 [[ 1.4361217  -0.01613045  2.3591251 ]\n",
      " [-0.10325202 -0.29120153 -0.21470045]\n",
      " [ 0.941904    1.0751065   0.2612581 ]]\n",
      "154 0.7158526 [[ 1.4297862  -0.01578784  2.365118  ]\n",
      " [-0.10238419 -0.2907968  -0.215973  ]\n",
      " [ 0.94355625  1.0748112   0.25990114]]\n",
      "155 0.7142614 [[ 1.4234827  -0.01544284  2.3710766 ]\n",
      " [-0.10152974 -0.29038984 -0.2172344 ]\n",
      " [ 0.9452087   1.0745124   0.25854757]]\n",
      "156 0.71268696 [[ 1.4172106  -0.01509543  2.3770013 ]\n",
      " [-0.10068842 -0.28998086 -0.21848468]\n",
      " [ 0.9468613   1.07421     0.25719726]]\n",
      "157 0.71112895 [[ 1.4109695  -0.01474559  2.3828926 ]\n",
      " [-0.09985999 -0.28957006 -0.21972391]\n",
      " [ 0.9485139   1.0739046   0.2558501 ]]\n",
      "158 0.70958704 [[ 1.404759   -0.01439333  2.3887508 ]\n",
      " [-0.09904413 -0.28915772 -0.22095212]\n",
      " [ 0.9501666   1.073596    0.254506  ]]\n",
      "159 0.708061 [[ 1.3985788  -0.01403861  2.3945763 ]\n",
      " [-0.09824076 -0.28874382 -0.2221694 ]\n",
      " [ 0.9518191   1.0732846   0.2531648 ]]\n",
      "160 0.70655036 [[ 1.3924283  -0.01368144  2.4003696 ]\n",
      " [-0.09744948 -0.2883287  -0.22337575]\n",
      " [ 0.95347154  1.0729705   0.25182647]]\n",
      "161 0.705055 [[ 1.3863071  -0.01332182  2.406131  ]\n",
      " [-0.09667017 -0.2879125  -0.22457126]\n",
      " [ 0.9551238   1.0726539   0.2504909 ]]\n",
      "162 0.70357466 [[ 1.380215   -0.01295975  2.411861  ]\n",
      " [-0.09590256 -0.2874954  -0.22575596]\n",
      " [ 0.9567758   1.0723348   0.24915802]]\n",
      "163 0.702109 [[ 1.3741516  -0.01259518  2.4175599 ]\n",
      " [-0.09514654 -0.28707743 -0.22692996]\n",
      " [ 0.9584274   1.0720135   0.24782771]]\n",
      "164 0.70065784 [[ 1.3681164  -0.01222816  2.423228  ]\n",
      " [-0.09440176 -0.28665885 -0.22809331]\n",
      " [ 0.9600788   1.07169     0.24649988]]\n",
      "165 0.6992207 [[ 1.3621091  -0.01185864  2.428866  ]\n",
      " [-0.09366817 -0.28623968 -0.22924607]\n",
      " [ 0.9617296   1.0713645   0.24517447]]\n",
      "166 0.6977978 [[ 1.3561293  -0.01148668  2.4344738 ]\n",
      " [-0.09294536 -0.28582028 -0.2303883 ]\n",
      " [ 0.9633801   1.071037    0.2438514 ]]\n",
      "167 0.6963884 [[ 1.3501767  -0.01111221  2.4400518 ]\n",
      " [-0.09223342 -0.28540045 -0.23152007]\n",
      " [ 0.96502995  1.070708    0.2425306 ]]\n",
      "168 0.69499254 [[ 1.3442509  -0.01073529  2.4456005 ]\n",
      " [-0.09153187 -0.28498062 -0.23264144]\n",
      " [ 0.9666794   1.0703772   0.24121201]]\n",
      "169 0.6936101 [[ 1.3383516  -0.01035588  2.4511204 ]\n",
      " [-0.09084076 -0.2845607  -0.23375247]\n",
      " [ 0.9683282   1.0700449   0.23989558]]\n",
      "170 0.6922406 [[ 1.3324785  -0.009974    2.4566116 ]\n",
      " [-0.09015982 -0.28414086 -0.23485325]\n",
      " [ 0.9699763   1.0697111   0.23858123]]\n",
      "171 0.69088364 [[ 1.3266313  -0.00958964  2.4620745 ]\n",
      " [-0.08948887 -0.28372118 -0.23594387]\n",
      " [ 0.9716237   1.069376    0.23726887]]\n",
      "172 0.68953955 [[ 1.3208096  -0.00920283  2.4675095 ]\n",
      " [-0.08882773 -0.2833018  -0.23702438]\n",
      " [ 0.9732705   1.0690397   0.23595847]]\n",
      "173 0.68820775 [[ 1.315013   -0.00881356  2.4729168 ]\n",
      " [-0.08817621 -0.28288284 -0.23809484]\n",
      " [ 0.97491646  1.0687022   0.23465002]]\n",
      "174 0.6868882 [[ 1.3092414  -0.00842184  2.4782968 ]\n",
      " [-0.0875342  -0.28246436 -0.23915534]\n",
      " [ 0.97656167  1.0683637   0.23334341]]\n",
      "175 0.68558055 [[ 1.3034943  -0.00802767  2.4836497 ]\n",
      " [-0.08690155 -0.28204638 -0.24020596]\n",
      " [ 0.978206    1.0680242   0.23203862]]\n",
      "176 0.6842846 [[ 1.2977715  -0.00763106  2.488976  ]\n",
      " [-0.08627805 -0.28162906 -0.24124677]\n",
      " [ 0.97984946  1.0676837   0.23073559]]\n",
      "177 0.6830004 [[ 1.2920727  -0.00723201  2.4942758 ]\n",
      " [-0.08566359 -0.28121242 -0.24227785]\n",
      " [ 0.98149204  1.0673424   0.22943428]]\n",
      "178 0.6817276 [[ 1.2863975  -0.00683054  2.4995494 ]\n",
      " [-0.08505799 -0.2807966  -0.24329928]\n",
      " [ 0.98313373  1.0670004   0.22813465]]\n",
      "179 0.6804659 [[ 1.2807457  -0.00642665  2.5047972 ]\n",
      " [-0.08446115 -0.2803816  -0.24431111]\n",
      " [ 0.9847744   1.0666577   0.22683667]]\n",
      "180 0.6792153 [[ 1.2751172  -0.00602035  2.5100195 ]\n",
      " [-0.08387288 -0.27996752 -0.24531344]\n",
      " [ 0.98641413  1.0663143   0.2255403 ]]\n",
      "181 0.6779754 [[ 1.2695115  -0.00561166  2.5152166 ]\n",
      " [-0.08329308 -0.27955443 -0.24630634]\n",
      " [ 0.9880528   1.0659704   0.22424549]]\n",
      "182 0.67674637 [[ 1.2639283  -0.00520058  2.5203886 ]\n",
      " [-0.08272158 -0.27914235 -0.24728993]\n",
      " [ 0.9896904   1.065626    0.22295219]]\n",
      "183 0.67552775 [[ 1.2583674  -0.00478713  2.525536  ]\n",
      " [-0.08215822 -0.2787314  -0.24826422]\n",
      " [ 0.99132705  1.0652812   0.22166042]]\n",
      "184 0.67431957 [[ 1.2528286  -0.0043713   2.530659  ]\n",
      " [-0.08160295 -0.27832153 -0.24922934]\n",
      " [ 0.9929625   1.064936    0.22037011]]\n",
      "185 0.6731216 [[ 1.2473116  -0.00395314  2.5357578 ]\n",
      " [-0.08105552 -0.27791297 -0.2501853 ]\n",
      " [ 0.9945969   1.0645905   0.21908128]]\n",
      "186 0.6719335 [[ 1.2418162  -0.00353263  2.5408328 ]\n",
      " [-0.08051597 -0.27750555 -0.25113228]\n",
      " [ 0.9962301   1.0642447   0.21779385]]\n",
      "187 0.67075527 [[ 1.2363421  -0.0031098   2.5458841 ]\n",
      " [-0.07998397 -0.27709955 -0.25207028]\n",
      " [ 0.9978623   1.0638987   0.21650784]]\n",
      "188 0.6695868 [[ 1.230889   -0.00268464  2.5509121 ]\n",
      " [-0.07945967 -0.27669474 -0.2529994 ]\n",
      " [ 0.99949306  1.0635525   0.2152232 ]]\n",
      "189 0.66842806 [[ 1.2254567e+00 -2.2571909e-03  2.5559170e+00]\n",
      " [-7.8942619e-02 -2.7629143e-01 -2.5391975e-01]\n",
      " [ 1.0011228e+00  1.0632061e+00  2.1393988e-01]]\n",
      "190 0.6672785 [[ 1.2200450e+00 -1.8274314e-03  2.5608990e+00]\n",
      " [-7.8433059e-02 -2.7588937e-01 -2.5483137e-01]\n",
      " [ 1.0027512e+00  1.0628597e+00  2.1265791e-01]]\n",
      "191 0.6661383 [[ 1.2146536e+00 -1.3954157e-03  2.5658584e+00]\n",
      " [-7.7930562e-02 -2.7548885e-01 -2.5573435e-01]\n",
      " [ 1.0043784e+00  1.0625131e+00  2.1137725e-01]]\n",
      "192 0.66500723 [[ 1.2092824e+00 -9.6113223e-04  2.5707953e+00]\n",
      " [-7.7435181e-02 -2.7508980e-01 -2.5662878e-01]\n",
      " [ 1.0060043e+00  1.0621666e+00  2.1009786e-01]]\n",
      "193 0.6638852 [[ 1.2039311e+00 -5.2460528e-04  2.5757101e+00]\n",
      " [-7.6946765e-02 -2.7469227e-01 -2.5751472e-01]\n",
      " [ 1.0076290e+00  1.0618200e+00  2.0881976e-01]]\n",
      "194 0.662772 [[ 1.1985995e+00 -8.5837586e-05  2.5806029e+00]\n",
      " [-7.6465257e-02 -2.7429622e-01 -2.5839224e-01]\n",
      " [ 1.0092523e+00  1.0614736e+00  2.0754294e-01]]\n",
      "195 0.6616676 [[ 1.1932873e+00  3.5513137e-04  2.5854740e+00]\n",
      " [-7.5990424e-02 -2.7390182e-01 -2.5926146e-01]\n",
      " [ 1.0108744e+00  1.0611271e+00  2.0626736e-01]]\n",
      "196 0.66057175 [[ 1.1879944e+00  7.9832913e-04  2.5903237e+00]\n",
      " [-7.5522378e-02 -2.7350885e-01 -2.6012245e-01]\n",
      " [ 1.0124950e+00  1.0607809e+00  2.0499299e-01]]\n",
      "197 0.6594843 [[ 1.1827205e+00  1.2436764e-03  2.5951521e+00]\n",
      " [-7.5060725e-02 -2.7311772e-01 -2.6097524e-01]\n",
      " [ 1.0141145e+00  1.0604346e+00  2.0371988e-01]]\n",
      "198 0.65840524 [[ 1.1774654e+00  1.6912451e-03  2.5999596e+00]\n",
      " [-7.4605770e-02 -2.7272797e-01 -2.6181996e-01]\n",
      " [ 1.0157323e+00  1.0600886e+00  2.0244797e-01]]\n",
      "199 0.65733457 [[ 1.1722291e+00  2.1409264e-03  2.6047463e+00]\n",
      " [-7.4156918e-02 -2.7234009e-01 -2.6265666e-01]\n",
      " [ 1.0173490e+00  1.0597427e+00  2.0117724e-01]]\n",
      "200 0.65627176 [[ 1.1670110e+00  2.5927923e-03  2.6095126e+00]\n",
      " [-7.3714569e-02 -2.7195364e-01 -2.6348543e-01]\n",
      " [ 1.0189641e+00  1.0593972e+00  1.9990769e-01]]\n",
      "Prediction : [2 2 2]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "# Evaluation our model using this test dataset\n",
    "# traning Data Set을 먼저 학습하고 Test set을 학습한 Model에 넣는다\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis),axis =1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis,1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        #Traning\n",
    "        cost_val,W_val,_ = sess.run([cost,W,optimizer],\n",
    "                                   feed_dict={X:x_data, Y:y_data})\n",
    "        print(step,cost_val,W_val)\n",
    "    \n",
    "    #Test\n",
    "    print(\"Prediction :\",sess.run(prediction,feed_dict={X:x_test}))\n",
    "    #calc Accuracy\n",
    "    print(\"Accuracy:\",sess.run(accuracy,feed_dict={X:x_test,Y:y_test}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.0281308 [[ 1.7348107   1.2917418  -1.8066033 ]\n",
      " [ 2.1753414   2.6340127  -3.2620056 ]\n",
      " [ 0.9761262   0.74997294 -5.587759  ]]\n",
      "1 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "2 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "3 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "4 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "5 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "6 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "7 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "8 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "9 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "10 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "11 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "12 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "13 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "14 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "15 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "16 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "17 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "18 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "19 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "20 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "21 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "22 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "23 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "24 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "25 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "26 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "27 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "28 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "29 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "30 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "31 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "32 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "33 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "34 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "35 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "36 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "37 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "38 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "39 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "40 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "41 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "42 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "43 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "44 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "45 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "46 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "47 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "48 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "49 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "50 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "51 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "52 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "53 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "54 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "55 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "56 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "57 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "58 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "59 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "60 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "61 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "62 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "63 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "64 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "65 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "66 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "67 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "68 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "69 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "70 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "71 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "72 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "73 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "74 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "75 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "76 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "77 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "78 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "79 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "80 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "81 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "82 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "83 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "84 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "85 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "86 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "87 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "88 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "89 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "90 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "91 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "92 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "93 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "94 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "95 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "96 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "97 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "98 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "99 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "100 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "101 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "102 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "103 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "104 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "105 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "106 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "107 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "108 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "109 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "110 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "111 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "112 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "113 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "114 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "115 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "116 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "117 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "118 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "119 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "120 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "121 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "122 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "123 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "124 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "125 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "126 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "127 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "128 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "129 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "130 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "131 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "132 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "133 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "134 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "135 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "136 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "137 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "138 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "139 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "140 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "141 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "142 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "143 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "144 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "145 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "146 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "147 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "148 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "149 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "150 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "151 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "152 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "153 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "154 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "155 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "156 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "157 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "158 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "159 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "160 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "161 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "162 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "163 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "164 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "165 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "166 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "167 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "168 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "169 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "170 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "171 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "172 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "173 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "174 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "175 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "176 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "177 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "178 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "179 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "180 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "181 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "182 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "183 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "185 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "186 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "187 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "188 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "189 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "190 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "191 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "192 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "193 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "194 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "195 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "196 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "197 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "198 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "199 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "200 nan [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Prediction : [0 0 0]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Learning Rate = 1.5 ( overShooting )\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis),axis =1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.5).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis,1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        #Traning\n",
    "        cost_val,W_val,_ = sess.run([cost,W,optimizer],\n",
    "                                   feed_dict={X:x_data, Y:y_data})\n",
    "        print(step,cost_val,W_val)\n",
    "    \n",
    "    #Test\n",
    "    print(\"Prediction :\",sess.run(prediction,feed_dict={X:x_test}))\n",
    "    #calc Accuracy\n",
    "    print(\"Accuracy:\",sess.run(accuracy,feed_dict={X:x_test,Y:y_test}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "1 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "2 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "3 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "4 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "5 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "6 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "7 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "8 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "9 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "10 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "11 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "12 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "13 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "14 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "15 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "16 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "17 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "18 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "19 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "20 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "21 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "22 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "23 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "24 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "25 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "26 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "27 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "28 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "29 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "30 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "31 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "32 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "33 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "34 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "35 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "36 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "37 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "38 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "39 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "40 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "41 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "42 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "43 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "44 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "45 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "46 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "47 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "48 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "49 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "50 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "51 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "52 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "53 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "54 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "55 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "56 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "57 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "58 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "59 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "60 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "61 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "62 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "63 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "64 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "65 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "66 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "67 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "68 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "69 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "70 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "71 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "72 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "73 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "74 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "75 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "76 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "77 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "78 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "79 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "80 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "81 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "82 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "83 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "84 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "85 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "86 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "87 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "88 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "90 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "91 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "92 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "93 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "94 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "95 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "96 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "97 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "98 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "99 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "100 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "101 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "102 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "103 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "104 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "105 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "106 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "107 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "108 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "109 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "110 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "111 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "112 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "113 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "114 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "115 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "116 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "117 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "118 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "119 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "120 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "121 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "122 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "123 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "124 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "125 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "126 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "127 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "128 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "129 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "130 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "131 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "132 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "133 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "134 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "135 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "136 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "137 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "138 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "139 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "140 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "141 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "142 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "143 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "144 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "145 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "146 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "147 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "148 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "149 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "150 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "151 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "152 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "153 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "154 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "155 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "156 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "157 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "158 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "159 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "160 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "161 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "162 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "163 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "164 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "165 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "166 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "167 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "168 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "169 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "170 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "171 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "172 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "173 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "174 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "175 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "176 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "177 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "178 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "179 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "180 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "181 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "182 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "183 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "184 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "185 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "186 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "187 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "188 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "190 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "191 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "192 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "193 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "194 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "195 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "196 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "197 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "198 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "199 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "200 10.950874 [[ 0.7438008  -0.45698187  0.25909874]\n",
      " [ 2.8620439   0.73891807  0.23120531]\n",
      " [ 1.1218731   0.45710415 -2.0219498 ]]\n",
      "Prediction : [0 0 0]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Learning Rate = very Small Learning Rate\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis),axis =1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis,1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        #Traning\n",
    "        cost_val,W_val,_ = sess.run([cost,W,optimizer],\n",
    "                                   feed_dict={X:x_data, Y:y_data})\n",
    "        print(step,cost_val,W_val)\n",
    "    \n",
    "    #Test\n",
    "    print(\"Prediction :\",sess.run(prediction,feed_dict={X:x_test}))\n",
    "    #calc Accuracy\n",
    "    print(\"Accuracy:\",sess.run(accuracy,feed_dict={X:x_test,Y:y_test}))\n",
    "\n",
    "    \n",
    "#Local Minimum에 빠져버리게됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  2.4014752 \n",
      "Prediction:\n",
      " [[1.8491496]\n",
      " [2.3205857]\n",
      " [2.105643 ]\n",
      " [1.8764119]\n",
      " [1.9692953]\n",
      " [1.9963529]\n",
      " [1.9157419]\n",
      " [2.1214194]]\n",
      "1 Cost:  2.401322 \n",
      "Prediction:\n",
      " [[1.8490821]\n",
      " [2.3205168]\n",
      " [2.105585 ]\n",
      " [1.8763664]\n",
      " [1.9692421]\n",
      " [1.9963013]\n",
      " [1.9157047]\n",
      " [2.1213818]]\n",
      "2 Cost:  2.4011686 \n",
      "Prediction:\n",
      " [[1.8490145]\n",
      " [2.320448 ]\n",
      " [2.105527 ]\n",
      " [1.8763207]\n",
      " [1.969189 ]\n",
      " [1.9962497]\n",
      " [1.9156675]\n",
      " [2.121344 ]]\n",
      "3 Cost:  2.4010155 \n",
      "Prediction:\n",
      " [[1.848947 ]\n",
      " [2.3203788]\n",
      " [2.105469 ]\n",
      " [1.8762752]\n",
      " [1.9691359]\n",
      " [1.996198 ]\n",
      " [1.9156303]\n",
      " [2.1213064]]\n",
      "4 Cost:  2.4008622 \n",
      "Prediction:\n",
      " [[1.8488796]\n",
      " [2.3203099]\n",
      " [2.105411 ]\n",
      " [1.8762295]\n",
      " [1.9690828]\n",
      " [1.9961464]\n",
      " [1.9155931]\n",
      " [2.1212687]]\n",
      "5 Cost:  2.4007092 \n",
      "Prediction:\n",
      " [[1.848812 ]\n",
      " [2.320241 ]\n",
      " [2.105353 ]\n",
      " [1.876184 ]\n",
      " [1.9690297]\n",
      " [1.9960948]\n",
      " [1.9155558]\n",
      " [2.121231 ]]\n",
      "6 Cost:  2.4005558 \n",
      "Prediction:\n",
      " [[1.8487445]\n",
      " [2.3201718]\n",
      " [2.1052952]\n",
      " [1.8761383]\n",
      " [1.9689765]\n",
      " [1.9960432]\n",
      " [1.9155186]\n",
      " [2.1211934]]\n",
      "7 Cost:  2.4004025 \n",
      "Prediction:\n",
      " [[1.8486769]\n",
      " [2.320103 ]\n",
      " [2.105237 ]\n",
      " [1.8760928]\n",
      " [1.9689234]\n",
      " [1.9959916]\n",
      " [1.9154814]\n",
      " [2.1211557]]\n",
      "8 Cost:  2.4002495 \n",
      "Prediction:\n",
      " [[1.8486094]\n",
      " [2.320034 ]\n",
      " [2.105179 ]\n",
      " [1.8760471]\n",
      " [1.9688703]\n",
      " [1.99594  ]\n",
      " [1.9154443]\n",
      " [2.121118 ]]\n",
      "9 Cost:  2.4000964 \n",
      "Prediction:\n",
      " [[1.848542 ]\n",
      " [2.319965 ]\n",
      " [2.1051211]\n",
      " [1.8760016]\n",
      " [1.9688172]\n",
      " [1.9958884]\n",
      " [1.9154071]\n",
      " [2.1210804]]\n",
      "10 Cost:  2.3999434 \n",
      "Prediction:\n",
      " [[1.8484744]\n",
      " [2.319896 ]\n",
      " [2.1050632]\n",
      " [1.8759559]\n",
      " [1.9687641]\n",
      " [1.9958367]\n",
      " [1.9153699]\n",
      " [2.1210427]]\n",
      "11 Cost:  2.3997898 \n",
      "Prediction:\n",
      " [[1.8484069]\n",
      " [2.319827 ]\n",
      " [2.1050053]\n",
      " [1.8759104]\n",
      " [1.9687109]\n",
      " [1.9957852]\n",
      " [1.9153326]\n",
      " [2.1210048]]\n",
      "12 Cost:  2.399637 \n",
      "Prediction:\n",
      " [[1.8483394]\n",
      " [2.3197582]\n",
      " [2.1049473]\n",
      " [1.8758647]\n",
      " [1.9686579]\n",
      " [1.9957336]\n",
      " [1.9152954]\n",
      " [2.1209671]]\n",
      "13 Cost:  2.3994837 \n",
      "Prediction:\n",
      " [[1.8482718]\n",
      " [2.319689 ]\n",
      " [2.1048892]\n",
      " [1.8758192]\n",
      " [1.9686047]\n",
      " [1.995682 ]\n",
      " [1.9152582]\n",
      " [2.1209295]]\n",
      "14 Cost:  2.3993306 \n",
      "Prediction:\n",
      " [[1.8482044]\n",
      " [2.3196201]\n",
      " [2.1048312]\n",
      " [1.8757735]\n",
      " [1.9685515]\n",
      " [1.9956304]\n",
      " [1.915221 ]\n",
      " [2.1208918]]\n",
      "15 Cost:  2.3991776 \n",
      "Prediction:\n",
      " [[1.8481369]\n",
      " [2.3195512]\n",
      " [2.1047733]\n",
      " [1.875728 ]\n",
      " [1.9684985]\n",
      " [1.9955788]\n",
      " [1.9151838]\n",
      " [2.1208541]]\n",
      "16 Cost:  2.3990245 \n",
      "Prediction:\n",
      " [[1.8480694]\n",
      " [2.3194823]\n",
      " [2.1047153]\n",
      " [1.8756824]\n",
      " [1.9684453]\n",
      " [1.9955271]\n",
      " [1.9151465]\n",
      " [2.1208165]]\n",
      "17 Cost:  2.3988712 \n",
      "Prediction:\n",
      " [[1.8480018]\n",
      " [2.3194132]\n",
      " [2.1046574]\n",
      " [1.8756368]\n",
      " [1.9683923]\n",
      " [1.9954755]\n",
      " [1.9151093]\n",
      " [2.1207788]]\n",
      "18 Cost:  2.3987184 \n",
      "Prediction:\n",
      " [[1.8479344]\n",
      " [2.3193443]\n",
      " [2.1045995]\n",
      " [1.8755913]\n",
      " [1.9683392]\n",
      " [1.9954239]\n",
      " [1.9150721]\n",
      " [2.1207411]]\n",
      "19 Cost:  2.398565 \n",
      "Prediction:\n",
      " [[1.8478669]\n",
      " [2.3192754]\n",
      " [2.1045413]\n",
      " [1.8755456]\n",
      " [1.968286 ]\n",
      " [1.9953723]\n",
      " [1.9150349]\n",
      " [2.1207035]]\n",
      "20 Cost:  2.3984122 \n",
      "Prediction:\n",
      " [[1.8477994]\n",
      " [2.3192065]\n",
      " [2.1044834]\n",
      " [1.8755001]\n",
      " [1.9682329]\n",
      " [1.9953208]\n",
      " [1.9149977]\n",
      " [2.1206658]]\n",
      "21 Cost:  2.3982592 \n",
      "Prediction:\n",
      " [[1.847732 ]\n",
      " [2.3191376]\n",
      " [2.1044254]\n",
      " [1.8754544]\n",
      " [1.9681798]\n",
      " [1.9952692]\n",
      " [1.9149605]\n",
      " [2.120628 ]]\n",
      "22 Cost:  2.3981059 \n",
      "Prediction:\n",
      " [[1.8476644]\n",
      " [2.3190684]\n",
      " [2.1043675]\n",
      " [1.8754089]\n",
      " [1.9681267]\n",
      " [1.9952176]\n",
      " [1.9149233]\n",
      " [2.1205904]]\n",
      "23 Cost:  2.397953 \n",
      "Prediction:\n",
      " [[1.8475969]\n",
      " [2.3189995]\n",
      " [2.1043096]\n",
      " [1.8753633]\n",
      " [1.9680736]\n",
      " [1.995166 ]\n",
      " [1.914886 ]\n",
      " [2.1205528]]\n",
      "24 Cost:  2.3978 \n",
      "Prediction:\n",
      " [[1.8475294]\n",
      " [2.3189306]\n",
      " [2.1042516]\n",
      " [1.8753177]\n",
      " [1.9680204]\n",
      " [1.9951143]\n",
      " [1.9148488]\n",
      " [2.120515 ]]\n",
      "25 Cost:  2.397647 \n",
      "Prediction:\n",
      " [[1.8474619]\n",
      " [2.3188617]\n",
      " [2.1041937]\n",
      " [1.8752722]\n",
      " [1.9679674]\n",
      " [1.9950628]\n",
      " [1.9148116]\n",
      " [2.1204774]]\n",
      "26 Cost:  2.3974938 \n",
      "Prediction:\n",
      " [[1.8473945]\n",
      " [2.3187928]\n",
      " [2.1041358]\n",
      " [1.8752265]\n",
      " [1.9679142]\n",
      " [1.9950112]\n",
      " [1.9147744]\n",
      " [2.1204398]]\n",
      "27 Cost:  2.3973408 \n",
      "Prediction:\n",
      " [[1.847327 ]\n",
      " [2.318724 ]\n",
      " [2.1040778]\n",
      " [1.875181 ]\n",
      " [1.9678612]\n",
      " [1.9949596]\n",
      " [1.9147372]\n",
      " [2.120402 ]]\n",
      "28 Cost:  2.3971877 \n",
      "Prediction:\n",
      " [[1.8472595]\n",
      " [2.3186548]\n",
      " [2.1040196]\n",
      " [1.8751354]\n",
      " [1.967808 ]\n",
      " [1.994908 ]\n",
      " [1.9147   ]\n",
      " [2.1203644]]\n",
      "29 Cost:  2.3970346 \n",
      "Prediction:\n",
      " [[1.847192 ]\n",
      " [2.3185859]\n",
      " [2.1039617]\n",
      " [1.8750898]\n",
      " [1.967755 ]\n",
      " [1.9948564]\n",
      " [1.9146628]\n",
      " [2.1203268]]\n",
      "30 Cost:  2.3968816 \n",
      "Prediction:\n",
      " [[1.8471246]\n",
      " [2.318517 ]\n",
      " [2.1039038]\n",
      " [1.8750442]\n",
      " [1.9677018]\n",
      " [1.9948049]\n",
      " [1.9146255]\n",
      " [2.120289 ]]\n",
      "31 Cost:  2.3967285 \n",
      "Prediction:\n",
      " [[1.847057 ]\n",
      " [2.318448 ]\n",
      " [2.1038458]\n",
      " [1.8749986]\n",
      " [1.9676487]\n",
      " [1.9947532]\n",
      " [1.9145883]\n",
      " [2.1202512]]\n",
      "32 Cost:  2.3965757 \n",
      "Prediction:\n",
      " [[1.8469896]\n",
      " [2.3183792]\n",
      " [2.103788 ]\n",
      " [1.874953 ]\n",
      " [1.9675956]\n",
      " [1.9947016]\n",
      " [1.9145511]\n",
      " [2.1202135]]\n",
      "33 Cost:  2.3964229 \n",
      "Prediction:\n",
      " [[1.846922 ]\n",
      " [2.3183103]\n",
      " [2.10373  ]\n",
      " [1.8749075]\n",
      " [1.9675425]\n",
      " [1.99465  ]\n",
      " [1.914514 ]\n",
      " [2.1201758]]\n",
      "34 Cost:  2.3962698 \n",
      "Prediction:\n",
      " [[1.8468547]\n",
      " [2.3182411]\n",
      " [2.103672 ]\n",
      " [1.8748618]\n",
      " [1.9674895]\n",
      " [1.9945984]\n",
      " [1.9144768]\n",
      " [2.1201382]]\n",
      "35 Cost:  2.3961167 \n",
      "Prediction:\n",
      " [[1.8467871]\n",
      " [2.3181722]\n",
      " [2.103614 ]\n",
      " [1.8748163]\n",
      " [1.9674363]\n",
      " [1.9945469]\n",
      " [1.9144396]\n",
      " [2.1201005]]\n",
      "36 Cost:  2.395964 \n",
      "Prediction:\n",
      " [[1.8467197]\n",
      " [2.3181033]\n",
      " [2.1035562]\n",
      " [1.8747708]\n",
      " [1.9673833]\n",
      " [1.9944953]\n",
      " [1.9144024]\n",
      " [2.1200628]]\n",
      "37 Cost:  2.395811 \n",
      "Prediction:\n",
      " [[1.8466523]\n",
      " [2.3180344]\n",
      " [2.1034982]\n",
      " [1.8747251]\n",
      " [1.9673301]\n",
      " [1.9944437]\n",
      " [1.9143652]\n",
      " [2.1200252]]\n",
      "38 Cost:  2.395658 \n",
      "Prediction:\n",
      " [[1.8465848]\n",
      " [2.3179655]\n",
      " [2.1034403]\n",
      " [1.8746796]\n",
      " [1.967277 ]\n",
      " [1.9943922]\n",
      " [1.9143279]\n",
      " [2.1199875]]\n",
      "39 Cost:  2.395505 \n",
      "Prediction:\n",
      " [[1.8465173]\n",
      " [2.3178966]\n",
      " [2.103382 ]\n",
      " [1.874634 ]\n",
      " [1.9672239]\n",
      " [1.9943405]\n",
      " [1.9142907]\n",
      " [2.1199498]]\n",
      "40 Cost:  2.3953521 \n",
      "Prediction:\n",
      " [[1.8464499]\n",
      " [2.3178277]\n",
      " [2.1033242]\n",
      " [1.8745884]\n",
      " [1.9671708]\n",
      " [1.9942889]\n",
      " [1.9142535]\n",
      " [2.1199121]]\n",
      "41 Cost:  2.3951993 \n",
      "Prediction:\n",
      " [[1.8463824]\n",
      " [2.3177588]\n",
      " [2.1032662]\n",
      " [1.8745428]\n",
      " [1.9671178]\n",
      " [1.9942374]\n",
      " [1.9142163]\n",
      " [2.1198745]]\n",
      "42 Cost:  2.3950462 \n",
      "Prediction:\n",
      " [[1.8463149]\n",
      " [2.31769  ]\n",
      " [2.1032083]\n",
      " [1.8744973]\n",
      " [1.9670646]\n",
      " [1.9941858]\n",
      " [1.9141791]\n",
      " [2.1198368]]\n",
      "43 Cost:  2.3948936 \n",
      "Prediction:\n",
      " [[1.8462474]\n",
      " [2.3176208]\n",
      " [2.1031504]\n",
      " [1.8744518]\n",
      " [1.9670116]\n",
      " [1.9941342]\n",
      " [1.9141419]\n",
      " [2.1197991]]\n",
      "44 Cost:  2.3947406 \n",
      "Prediction:\n",
      " [[1.84618  ]\n",
      " [2.3175519]\n",
      " [2.1030924]\n",
      " [1.8744061]\n",
      " [1.9669585]\n",
      " [1.9940827]\n",
      " [1.9141047]\n",
      " [2.1197615]]\n",
      "45 Cost:  2.3945878 \n",
      "Prediction:\n",
      " [[1.8461126]\n",
      " [2.317483 ]\n",
      " [2.1030345]\n",
      " [1.8743606]\n",
      " [1.9669054]\n",
      " [1.9940311]\n",
      " [1.9140674]\n",
      " [2.1197238]]\n",
      "46 Cost:  2.394435 \n",
      "Prediction:\n",
      " [[1.8460451]\n",
      " [2.317414 ]\n",
      " [2.1029766]\n",
      " [1.874315 ]\n",
      " [1.9668523]\n",
      " [1.9939795]\n",
      " [1.9140302]\n",
      " [2.1196861]]\n",
      "47 Cost:  2.394282 \n",
      "Prediction:\n",
      " [[1.8459777]\n",
      " [2.3173451]\n",
      " [2.1029186]\n",
      " [1.8742695]\n",
      " [1.9667993]\n",
      " [1.993928 ]\n",
      " [1.913993 ]\n",
      " [2.1196485]]\n",
      "48 Cost:  2.3941293 \n",
      "Prediction:\n",
      " [[1.8459102]\n",
      " [2.3172762]\n",
      " [2.1028607]\n",
      " [1.8742238]\n",
      " [1.9667461]\n",
      " [1.9938763]\n",
      " [1.9139558]\n",
      " [2.1196108]]\n",
      "49 Cost:  2.3939762 \n",
      "Prediction:\n",
      " [[1.8458427]\n",
      " [2.3172073]\n",
      " [2.1028028]\n",
      " [1.8741783]\n",
      " [1.966693 ]\n",
      " [1.9938247]\n",
      " [1.9139186]\n",
      " [2.119573 ]]\n",
      "50 Cost:  2.3938236 \n",
      "Prediction:\n",
      " [[1.8457754]\n",
      " [2.3171384]\n",
      " [2.1027448]\n",
      " [1.8741328]\n",
      " [1.96664  ]\n",
      " [1.9937732]\n",
      " [1.9138814]\n",
      " [2.1195354]]\n",
      "51 Cost:  2.3936708 \n",
      "Prediction:\n",
      " [[1.8457079]\n",
      " [2.3170695]\n",
      " [2.102687 ]\n",
      " [1.8740871]\n",
      " [1.9665868]\n",
      " [1.9937216]\n",
      " [1.9138442]\n",
      " [2.1194978]]\n",
      "52 Cost:  2.3935177 \n",
      "Prediction:\n",
      " [[1.8456404]\n",
      " [2.3170006]\n",
      " [2.102629 ]\n",
      " [1.8740416]\n",
      " [1.9665338]\n",
      " [1.99367  ]\n",
      " [1.913807 ]\n",
      " [2.11946  ]]\n",
      "53 Cost:  2.3933651 \n",
      "Prediction:\n",
      " [[1.845573 ]\n",
      " [2.3169317]\n",
      " [2.102571 ]\n",
      " [1.873996 ]\n",
      " [1.9664807]\n",
      " [1.9936185]\n",
      " [1.9137698]\n",
      " [2.1194224]]\n",
      "54 Cost:  2.3932123 \n",
      "Prediction:\n",
      " [[1.8455056]\n",
      " [2.3168628]\n",
      " [2.102513 ]\n",
      " [1.8739505]\n",
      " [1.9664276]\n",
      " [1.9935669]\n",
      " [1.9137326]\n",
      " [2.1193848]]\n",
      "55 Cost:  2.3930595 \n",
      "Prediction:\n",
      " [[1.8454381]\n",
      " [2.316794 ]\n",
      " [2.1024551]\n",
      " [1.873905 ]\n",
      " [1.9663746]\n",
      " [1.9935153]\n",
      " [1.9136955]\n",
      " [2.119347 ]]\n",
      "56 Cost:  2.3929067 \n",
      "Prediction:\n",
      " [[1.8453707]\n",
      " [2.316725 ]\n",
      " [2.1023972]\n",
      " [1.8738593]\n",
      " [1.9663215]\n",
      " [1.9934638]\n",
      " [1.9136583]\n",
      " [2.1193094]]\n",
      "57 Cost:  2.392754 \n",
      "Prediction:\n",
      " [[1.8453032]\n",
      " [2.316656 ]\n",
      " [2.1023393]\n",
      " [1.8738137]\n",
      " [1.9662684]\n",
      " [1.9934121]\n",
      " [1.913621 ]\n",
      " [2.1192718]]\n",
      "58 Cost:  2.392601 \n",
      "Prediction:\n",
      " [[1.8452358]\n",
      " [2.3165872]\n",
      " [2.1022813]\n",
      " [1.8737682]\n",
      " [1.9662154]\n",
      " [1.9933606]\n",
      " [1.9135838]\n",
      " [2.119234 ]]\n",
      "59 Cost:  2.3924484 \n",
      "Prediction:\n",
      " [[1.8451684]\n",
      " [2.3165183]\n",
      " [2.1022234]\n",
      " [1.8737227]\n",
      " [1.9661622]\n",
      " [1.993309 ]\n",
      " [1.9135466]\n",
      " [2.1191964]]\n",
      "60 Cost:  2.3922958 \n",
      "Prediction:\n",
      " [[1.8451009]\n",
      " [2.3164494]\n",
      " [2.1021657]\n",
      " [1.873677 ]\n",
      " [1.9661092]\n",
      " [1.9932575]\n",
      " [1.9135094]\n",
      " [2.1191587]]\n",
      "61 Cost:  2.3921428 \n",
      "Prediction:\n",
      " [[1.8450335]\n",
      " [2.3163805]\n",
      " [2.1021078]\n",
      " [1.8736315]\n",
      " [1.9660561]\n",
      " [1.9932059]\n",
      " [1.9134722]\n",
      " [2.119121 ]]\n",
      "62 Cost:  2.3919902 \n",
      "Prediction:\n",
      " [[1.844966 ]\n",
      " [2.3163118]\n",
      " [2.1020498]\n",
      " [1.8735859]\n",
      " [1.9660031]\n",
      " [1.9931544]\n",
      " [1.913435 ]\n",
      " [2.1190834]]\n",
      "63 Cost:  2.3918378 \n",
      "Prediction:\n",
      " [[1.8448987]\n",
      " [2.316243 ]\n",
      " [2.101992 ]\n",
      " [1.8735405]\n",
      " [1.9659501]\n",
      " [1.9931029]\n",
      " [1.9133979]\n",
      " [2.1190457]]\n",
      "64 Cost:  2.3916857 \n",
      "Prediction:\n",
      " [[1.8448315]\n",
      " [2.3161743]\n",
      " [2.1019342]\n",
      " [1.8734951]\n",
      " [1.9658972]\n",
      " [1.9930515]\n",
      " [1.9133608]\n",
      " [2.1190083]]\n",
      "65 Cost:  2.3915334 \n",
      "Prediction:\n",
      " [[1.8447641]\n",
      " [2.3161054]\n",
      " [2.1018765]\n",
      " [1.8734497]\n",
      " [1.9658442]\n",
      " [1.993    ]\n",
      " [1.9133238]\n",
      " [2.1189709]]\n",
      "66 Cost:  2.3913808 \n",
      "Prediction:\n",
      " [[1.8446969]\n",
      " [2.3160367]\n",
      " [2.1018186]\n",
      " [1.8734041]\n",
      " [1.9657912]\n",
      " [1.9929487]\n",
      " [1.9132867]\n",
      " [2.1189332]]\n",
      "67 Cost:  2.3912287 \n",
      "Prediction:\n",
      " [[1.8446295]\n",
      " [2.315968 ]\n",
      " [2.1017609]\n",
      " [1.8733587]\n",
      " [1.9657383]\n",
      " [1.9928972]\n",
      " [1.9132496]\n",
      " [2.1188955]]\n",
      "68 Cost:  2.3910763 \n",
      "Prediction:\n",
      " [[1.8445623]\n",
      " [2.3158994]\n",
      " [2.101703 ]\n",
      " [1.8733133]\n",
      " [1.9656854]\n",
      " [1.9928458]\n",
      " [1.9132125]\n",
      " [2.118858 ]]\n",
      "69 Cost:  2.390924 \n",
      "Prediction:\n",
      " [[1.844495 ]\n",
      " [2.3158305]\n",
      " [2.1016452]\n",
      " [1.8732679]\n",
      " [1.9656324]\n",
      " [1.9927943]\n",
      " [1.9131755]\n",
      " [2.1188207]]\n",
      "70 Cost:  2.3907719 \n",
      "Prediction:\n",
      " [[1.8444277]\n",
      " [2.3157618]\n",
      " [2.1015875]\n",
      " [1.8732225]\n",
      " [1.9655795]\n",
      " [1.9927429]\n",
      " [1.9131384]\n",
      " [2.118783 ]]\n",
      "71 Cost:  2.3906195 \n",
      "Prediction:\n",
      " [[1.8443605]\n",
      " [2.315693 ]\n",
      " [2.1015296]\n",
      " [1.873177 ]\n",
      " [1.9655266]\n",
      " [1.9926915]\n",
      " [1.9131013]\n",
      " [2.1187456]]\n",
      "72 Cost:  2.3904672 \n",
      "Prediction:\n",
      " [[1.8442931]\n",
      " [2.3156242]\n",
      " [2.101472 ]\n",
      " [1.8731316]\n",
      " [1.9654737]\n",
      " [1.99264  ]\n",
      " [1.9130642]\n",
      " [2.118708 ]]\n",
      "73 Cost:  2.390315 \n",
      "Prediction:\n",
      " [[1.8442259]\n",
      " [2.3155556]\n",
      " [2.1014142]\n",
      " [1.8730862]\n",
      " [1.9654207]\n",
      " [1.9925886]\n",
      " [1.9130272]\n",
      " [2.1186705]]\n",
      "74 Cost:  2.390163 \n",
      "Prediction:\n",
      " [[1.8441585]\n",
      " [2.315487 ]\n",
      " [2.1013563]\n",
      " [1.8730408]\n",
      " [1.9653678]\n",
      " [1.9925373]\n",
      " [1.9129901]\n",
      " [2.1186328]]\n",
      "75 Cost:  2.3900104 \n",
      "Prediction:\n",
      " [[1.8440913]\n",
      " [2.315418 ]\n",
      " [2.1012986]\n",
      " [1.8729953]\n",
      " [1.9653149]\n",
      " [1.9924858]\n",
      " [1.912953 ]\n",
      " [2.1185954]]\n",
      "76 Cost:  2.3898582 \n",
      "Prediction:\n",
      " [[1.844024 ]\n",
      " [2.3153493]\n",
      " [2.1012409]\n",
      " [1.8729498]\n",
      " [1.9652619]\n",
      " [1.9924344]\n",
      " [1.912916 ]\n",
      " [2.1185577]]\n",
      "77 Cost:  2.389706 \n",
      "Prediction:\n",
      " [[1.8439567]\n",
      " [2.3152804]\n",
      " [2.101183 ]\n",
      " [1.8729044]\n",
      " [1.965209 ]\n",
      " [1.9923829]\n",
      " [1.9128789]\n",
      " [2.1185203]]\n",
      "78 Cost:  2.3895535 \n",
      "Prediction:\n",
      " [[1.8438895]\n",
      " [2.3152118]\n",
      " [2.1011252]\n",
      " [1.872859 ]\n",
      " [1.9651561]\n",
      " [1.9923315]\n",
      " [1.9128418]\n",
      " [2.1184826]]\n",
      "79 Cost:  2.3894014 \n",
      "Prediction:\n",
      " [[1.8438221]\n",
      " [2.315143 ]\n",
      " [2.1010675]\n",
      " [1.8728136]\n",
      " [1.9651031]\n",
      " [1.99228  ]\n",
      " [1.9128047]\n",
      " [2.1184452]]\n",
      "80 Cost:  2.3892493 \n",
      "Prediction:\n",
      " [[1.8437549]\n",
      " [2.3150744]\n",
      " [2.1010096]\n",
      " [1.8727682]\n",
      " [1.9650502]\n",
      " [1.9922286]\n",
      " [1.9127676]\n",
      " [2.1184077]]\n",
      "81 Cost:  2.3890972 \n",
      "Prediction:\n",
      " [[1.8436875]\n",
      " [2.3150058]\n",
      " [2.100952 ]\n",
      " [1.8727227]\n",
      " [1.9649973]\n",
      " [1.9921772]\n",
      " [1.9127306]\n",
      " [2.11837  ]]\n",
      "82 Cost:  2.388945 \n",
      "Prediction:\n",
      " [[1.8436203]\n",
      " [2.3149369]\n",
      " [2.1008942]\n",
      " [1.8726773]\n",
      " [1.9649444]\n",
      " [1.9921257]\n",
      " [1.9126935]\n",
      " [2.1183326]]\n",
      "83 Cost:  2.3887925 \n",
      "Prediction:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[1.8435531]\n",
      " [2.3148682]\n",
      " [2.1008363]\n",
      " [1.8726319]\n",
      " [1.9648914]\n",
      " [1.9920744]\n",
      " [1.9126564]\n",
      " [2.118295 ]]\n",
      "84 Cost:  2.3886404 \n",
      "Prediction:\n",
      " [[1.8434857]\n",
      " [2.3147993]\n",
      " [2.1007786]\n",
      " [1.8725865]\n",
      " [1.9648385]\n",
      " [1.992023 ]\n",
      " [1.9126194]\n",
      " [2.1182575]]\n",
      "85 Cost:  2.3884883 \n",
      "Prediction:\n",
      " [[1.8434185]\n",
      " [2.3147306]\n",
      " [2.100721 ]\n",
      " [1.8725411]\n",
      " [1.9647856]\n",
      " [1.9919715]\n",
      " [1.9125823]\n",
      " [2.1182199]]\n",
      "86 Cost:  2.3883362 \n",
      "Prediction:\n",
      " [[1.8433512]\n",
      " [2.314662 ]\n",
      " [2.100663 ]\n",
      " [1.8724957]\n",
      " [1.9647326]\n",
      " [1.9919201]\n",
      " [1.9125452]\n",
      " [2.1181824]]\n",
      "87 Cost:  2.388184 \n",
      "Prediction:\n",
      " [[1.8432839]\n",
      " [2.3145933]\n",
      " [2.1006052]\n",
      " [1.8724501]\n",
      " [1.9646797]\n",
      " [1.9918687]\n",
      " [1.9125081]\n",
      " [2.1181448]]\n",
      "88 Cost:  2.388032 \n",
      "Prediction:\n",
      " [[1.8432167]\n",
      " [2.3145244]\n",
      " [2.1005476]\n",
      " [1.8724047]\n",
      " [1.9646268]\n",
      " [1.9918172]\n",
      " [1.912471 ]\n",
      " [2.1181073]]\n",
      "89 Cost:  2.3878796 \n",
      "Prediction:\n",
      " [[1.8431494]\n",
      " [2.3144557]\n",
      " [2.1004896]\n",
      " [1.8723593]\n",
      " [1.9645737]\n",
      " [1.9917659]\n",
      " [1.912434 ]\n",
      " [2.1180696]]\n",
      "90 Cost:  2.3877277 \n",
      "Prediction:\n",
      " [[1.8430821]\n",
      " [2.314387 ]\n",
      " [2.100432 ]\n",
      " [1.8723139]\n",
      " [1.9645208]\n",
      " [1.9917145]\n",
      " [1.9123969]\n",
      " [2.1180322]]\n",
      "91 Cost:  2.3875754 \n",
      "Prediction:\n",
      " [[1.8430148]\n",
      " [2.3143184]\n",
      " [2.1003742]\n",
      " [1.8722684]\n",
      " [1.964468 ]\n",
      " [1.991663 ]\n",
      " [1.9123598]\n",
      " [2.1179945]]\n",
      "92 Cost:  2.3874235 \n",
      "Prediction:\n",
      " [[1.8429476]\n",
      " [2.3142495]\n",
      " [2.1003165]\n",
      " [1.872223 ]\n",
      " [1.9644151]\n",
      " [1.9916116]\n",
      " [1.9123228]\n",
      " [2.117957 ]]\n",
      "93 Cost:  2.3872712 \n",
      "Prediction:\n",
      " [[1.8428804]\n",
      " [2.3141809]\n",
      " [2.1002586]\n",
      " [1.8721776]\n",
      " [1.9643621]\n",
      " [1.9915602]\n",
      " [1.9122857]\n",
      " [2.1179194]]\n",
      "94 Cost:  2.3871193 \n",
      "Prediction:\n",
      " [[1.8428131]\n",
      " [2.3141122]\n",
      " [2.100201 ]\n",
      " [1.8721322]\n",
      " [1.9643092]\n",
      " [1.9915087]\n",
      " [1.9122486]\n",
      " [2.117882 ]]\n",
      "95 Cost:  2.3869672 \n",
      "Prediction:\n",
      " [[1.8427459]\n",
      " [2.3140435]\n",
      " [2.1001432]\n",
      " [1.8720868]\n",
      " [1.9642563]\n",
      " [1.9914573]\n",
      " [1.9122115]\n",
      " [2.1178446]]\n",
      "96 Cost:  2.3868148 \n",
      "Prediction:\n",
      " [[1.8426787]\n",
      " [2.3139749]\n",
      " [2.1000853]\n",
      " [1.8720413]\n",
      " [1.9642034]\n",
      " [1.991406 ]\n",
      " [1.9121745]\n",
      " [2.117807 ]]\n",
      "97 Cost:  2.386663 \n",
      "Prediction:\n",
      " [[1.8426114]\n",
      " [2.3139062]\n",
      " [2.1000276]\n",
      " [1.8719959]\n",
      " [1.9641504]\n",
      " [1.9913546]\n",
      " [1.9121374]\n",
      " [2.1177695]]\n",
      "98 Cost:  2.3865108 \n",
      "Prediction:\n",
      " [[1.8425442]\n",
      " [2.3138373]\n",
      " [2.0999699]\n",
      " [1.8719506]\n",
      " [1.9640975]\n",
      " [1.9913032]\n",
      " [1.9121003]\n",
      " [2.1177318]]\n",
      "99 Cost:  2.386359 \n",
      "Prediction:\n",
      " [[1.842477 ]\n",
      " [2.3137686]\n",
      " [2.0999122]\n",
      " [1.8719051]\n",
      " [1.9640447]\n",
      " [1.9912517]\n",
      " [1.9120632]\n",
      " [2.1176944]]\n",
      "100 Cost:  2.3862066 \n",
      "Prediction:\n",
      " [[1.8424097]\n",
      " [2.3137   ]\n",
      " [2.0998542]\n",
      " [1.8718598]\n",
      " [1.9639918]\n",
      " [1.9912003]\n",
      " [1.9120262]\n",
      " [2.1176567]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "#Normalized inputs\n",
    "xy = MinMaxScaler().fit_transform(xy) \n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
