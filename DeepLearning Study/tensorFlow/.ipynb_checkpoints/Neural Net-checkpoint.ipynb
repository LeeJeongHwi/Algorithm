{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wjdgn\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0446839\n",
      "100 0.69482416\n",
      "200 0.6941967\n",
      "300 0.69394314\n",
      "400 0.6937533\n",
      "500 0.6936037\n",
      "600 0.69347924\n",
      "700 0.6933702\n",
      "800 0.69326967\n",
      "900 0.69317305\n",
      "1000 0.69307625\n",
      "1100 0.69297653\n",
      "1200 0.69287086\n",
      "1300 0.6927564\n",
      "1400 0.69263005\n",
      "1500 0.6924883\n",
      "1600 0.6923269\n",
      "1700 0.6921408\n",
      "1800 0.69192356\n",
      "1900 0.6916671\n",
      "2000 0.6913608\n",
      "2100 0.69099087\n",
      "2200 0.6905395\n",
      "2300 0.6899828\n",
      "2400 0.689289\n",
      "2500 0.6884153\n",
      "2600 0.6873041\n",
      "2700 0.6858768\n",
      "2800 0.68402696\n",
      "2900 0.6816094\n",
      "3000 0.67842686\n",
      "3100 0.6742118\n",
      "3200 0.6686032\n",
      "3300 0.66111606\n",
      "3400 0.6511058\n",
      "3500 0.63772833\n",
      "3600 0.61991614\n",
      "3700 0.5964199\n",
      "3800 0.56602764\n",
      "3900 0.5280793\n",
      "4000 0.48319817\n",
      "4100 0.43371397\n",
      "4200 0.38316265\n",
      "4300 0.33503017\n",
      "4400 0.29168937\n",
      "4500 0.25413927\n",
      "4600 0.22234848\n",
      "4700 0.1957364\n",
      "4800 0.17353238\n",
      "4900 0.15497358\n",
      "5000 0.13938755\n",
      "5100 0.12621452\n",
      "5200 0.11500147\n",
      "5300 0.10538684\n",
      "5400 0.097082704\n",
      "5500 0.08986035\n",
      "5600 0.08353704\n",
      "5700 0.07796637\n",
      "5800 0.07302994\n",
      "5900 0.068631664\n",
      "6000 0.064692944\n",
      "6100 0.061149083\n",
      "6200 0.057946466\n",
      "6300 0.05504039\n",
      "6400 0.052393287\n",
      "6500 0.049973458\n",
      "6600 0.04775411\n",
      "6700 0.045712184\n",
      "6800 0.04382806\n",
      "6900 0.042084802\n",
      "7000 0.040467713\n",
      "7100 0.03896403\n",
      "7200 0.037562642\n",
      "7300 0.036253747\n",
      "7400 0.0350288\n",
      "7500 0.0338801\n",
      "7600 0.032801095\n",
      "7700 0.03178573\n",
      "7800 0.030828647\n",
      "7900 0.029925212\n",
      "8000 0.029071087\n",
      "8100 0.02826239\n",
      "8200 0.027495831\n",
      "8300 0.02676816\n",
      "8400 0.026076566\n",
      "8500 0.025418557\n",
      "8600 0.02479171\n",
      "8700 0.024194017\n",
      "8800 0.02362345\n",
      "8900 0.023078268\n",
      "9000 0.022556815\n",
      "9100 0.022057712\n",
      "9200 0.021579474\n",
      "9300 0.02112087\n",
      "9400 0.020680748\n",
      "9500 0.020258034\n",
      "9600 0.019851787\n",
      "9700 0.01946099\n",
      "9800 0.01908483\n",
      "9900 0.018722516\n",
      "10000 0.018373305\n",
      "hypothesis : [[0.01785873]\n",
      " [0.98357534]\n",
      " [0.97653085]\n",
      " [0.01503528]]\n",
      "correct: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "x_data= np.array([[0,0],[0,1],[1,0],[1,1]],dtype= np.float32)\n",
    "y_data= np.array([[0],[1],[1],[0]],dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "#Neural Net\n",
    "#layer2에게 줄 input을 잘 설정해주어야 한다\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    w = tf.Variable(tf.random_normal([2,2]),name='weight') \n",
    "    b = tf.Variable(tf.random_normal([2]),name='bias')\n",
    "    layer1= tf.sigmoid(tf.matmul(X,w)+b) \n",
    "    \n",
    "    tf.summary.histogram(\"W1\",w)\n",
    "    tf.summary.histogram(\"b1\",b)\n",
    "    tf.summary.histogram(\"Layer1\",layer1)\n",
    "with tf.name_scope(\"layer2\"):    \n",
    "    w2 = tf.Variable(tf.random_normal([2,1]),name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]),name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1,w2)+b2)\n",
    "\n",
    "    tf.summary.histogram('W2',w2)\n",
    "    tf.summary.histogram(\"b2\",b2)\n",
    "    tf.summary.histogram(\"Hypothesis\",hypothesis)\n",
    "\n",
    "#....여기에 레이어를 더 추가시킬 수 있다. input 과 output을 제대로만 설정하면됨\n",
    "#레이어가 많아질수록 hypothesis의 값이 더 명확해짐\n",
    "\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "    tf.summary.scalar(\"Cost\",cost)\n",
    "with tf.name_scope(\"Train\"):\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate= 0.1).minimize(cost)\n",
    "    \n",
    "    \n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y),dtype=tf.float32))\n",
    "tf.summary.scalar(\"Accuracy\",accuracy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged_summary=tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./logs/xor_logs')\n",
    "    writer.add_graph(sess.graph)\n",
    "   \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        _,summary,cost_val = sess.run(\n",
    "            [train,merged_summary,cost],feed_dict={X:x_data,Y:y_data})\n",
    "        writer.add_summary(summary,global_step=step)\n",
    "        if step%100 == 0:\n",
    "            print(step,cost_val)\n",
    "    \n",
    "\n",
    "    h,c,a = sess.run([hypothesis,predicted,accuracy],feed_dict={X:x_data,Y:y_data})\n",
    "    print(\"hypothesis :\",h)\n",
    "    print(\"correct:\",c)\n",
    "    print(\"accuracy\",a)\n",
    "    \n",
    "#command line\n",
    "# tensorboard --logdir=directory  #주의점 : 띄어쓰기할시 경로를 잘 못찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch :  0001 cost = 2.322553173\n",
      "Epoch :  0002 cost = 2.084525487\n",
      "Epoch :  0003 cost = 1.900485491\n",
      "Epoch :  0004 cost = 1.728047655\n",
      "Epoch :  0005 cost = 1.614167027\n",
      "Epoch :  0006 cost = 1.551186908\n",
      "Epoch :  0007 cost = 1.512164751\n",
      "Epoch :  0008 cost = 1.480778266\n",
      "Epoch :  0009 cost = 1.448841591\n",
      "Epoch :  0010 cost = 1.413816909\n",
      "Epoch :  0011 cost = 1.376398559\n",
      "Epoch :  0012 cost = 1.339563264\n",
      "Epoch :  0013 cost = 1.302980168\n",
      "Epoch :  0014 cost = 1.265410536\n",
      "Epoch :  0015 cost = 1.229484405\n",
      "Epoch :  0016 cost = 1.199491483\n",
      "Epoch :  0017 cost = 1.175472382\n",
      "Epoch :  0018 cost = 1.155542209\n",
      "Epoch :  0019 cost = 1.137874661\n",
      "Epoch :  0020 cost = 1.121029451\n",
      "Epoch :  0021 cost = 1.106616948\n",
      "Epoch :  0022 cost = 1.093728178\n",
      "Epoch :  0023 cost = 1.081119603\n",
      "Epoch :  0024 cost = 1.068214815\n",
      "Epoch :  0025 cost = 1.057734018\n",
      "Epoch :  0026 cost = 1.047367200\n",
      "Epoch :  0027 cost = 1.037118363\n",
      "Epoch :  0028 cost = 1.026465686\n",
      "Epoch :  0029 cost = 1.014511092\n",
      "Epoch :  0030 cost = 1.003786124\n",
      "Epoch :  0031 cost = 0.992741622\n",
      "Epoch :  0032 cost = 0.983030474\n",
      "Epoch :  0033 cost = 0.973989105\n",
      "Epoch :  0034 cost = 0.966566210\n",
      "Epoch :  0035 cost = 0.958888925\n",
      "Epoch :  0036 cost = 0.952067148\n",
      "Epoch :  0037 cost = 0.945291597\n",
      "Epoch :  0038 cost = 0.938869632\n",
      "Epoch :  0039 cost = 0.933010665\n",
      "Epoch :  0040 cost = 0.927264694\n",
      "Epoch :  0041 cost = 0.921874682\n",
      "Epoch :  0042 cost = 0.916891613\n",
      "Epoch :  0043 cost = 0.911241948\n",
      "Epoch :  0044 cost = 0.906398059\n",
      "Epoch :  0045 cost = 0.901274051\n",
      "Epoch :  0046 cost = 0.896367392\n",
      "Epoch :  0047 cost = 0.891282883\n",
      "Epoch :  0048 cost = 0.885627070\n",
      "Epoch :  0049 cost = 0.879207573\n",
      "Epoch :  0050 cost = 0.871233256\n",
      "Epoch :  0051 cost = 0.860212951\n",
      "Epoch :  0052 cost = 0.846599709\n",
      "Epoch :  0053 cost = 0.829953926\n",
      "Epoch :  0054 cost = 0.809032771\n",
      "Epoch :  0055 cost = 0.788734699\n",
      "Epoch :  0056 cost = 0.767583101\n",
      "Epoch :  0057 cost = 0.748555650\n",
      "Epoch :  0058 cost = 0.732421449\n",
      "Epoch :  0059 cost = 0.718711985\n",
      "Epoch :  0060 cost = 0.707314382\n",
      "Epoch :  0061 cost = 0.697191895\n",
      "Epoch :  0062 cost = 0.687605121\n",
      "Epoch :  0063 cost = 0.679056629\n",
      "Epoch :  0064 cost = 0.671830786\n",
      "Epoch :  0065 cost = 0.664339432\n",
      "Epoch :  0066 cost = 0.658526338\n",
      "Epoch :  0067 cost = 0.652234523\n",
      "Epoch :  0068 cost = 0.646826878\n",
      "Epoch :  0069 cost = 0.641643979\n",
      "Epoch :  0070 cost = 0.636831664\n",
      "Epoch :  0071 cost = 0.632596177\n",
      "Epoch :  0072 cost = 0.627966598\n",
      "Epoch :  0073 cost = 0.623837618\n",
      "Epoch :  0074 cost = 0.619669412\n",
      "Epoch :  0075 cost = 0.616365730\n",
      "Accuracy:  0.7669\n",
      "Label: [6]\n",
      "Prediction: [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mnist _ Test\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist= input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "nb_classes=10\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([784,50]),name='weight')\n",
    "b1 = tf.Variable(tf.random_normal([50]),name='bias')\n",
    "layer1 = tf.nn.softmax(tf.matmul(X,w1)+b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([50,40]),name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([40]),name='bias2')\n",
    "layer2 = tf.nn.softmax(tf.matmul(layer1,w2)+b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([40,nb_classes]),name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([nb_classes]),name='bias3')\n",
    "hypothesis = tf.nn.softmax(tf.matmul(layer2,w3)+b3)\n",
    "\n",
    "cost= tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis),axis=1))\n",
    "optimizer= tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predict = tf.equal(tf.arg_max(hypothesis,1),tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict,tf.float32))\n",
    "\n",
    "training_epochs=75\n",
    "## Layer가 늘어날 수록 Epochs의 크기도 커져야 정확성이 높아진다.\n",
    "batch_size=100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs , batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c,_=sess.run([cost,optimizer],feed_dict={X:batch_xs,Y:batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch : \",\"%04d\" % (epoch+1),\"cost =\",\"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X:mnist.test.images,Y:mnist.test.labels}))\n",
    "    r = random.randint(0,mnist.test.num_examples -1)\n",
    "    print(\"Label:\",sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "    print(\"Prediction:\",sess.run(tf.argmax(hypothesis,1),feed_dict={X:mnist.test.images[r:r+1]}))\n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap ='Greys',interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
